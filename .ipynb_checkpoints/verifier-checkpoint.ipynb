{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dd58604-2ccf-45e2-9296-238fdecf3393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import constants\n",
    "from channel import Channel\n",
    "from field import FieldElement\n",
    "from merkle import verify_decommitment\n",
    "from poseidon import generate_cauchy_matrix\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27a6712a-42e1-4187-89c5-1a3210589c5d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:31: SyntaxWarning: invalid escape sequence '\\|'\n",
      "<>:31: SyntaxWarning: invalid escape sequence '\\|'\n",
      "/tmp/ipykernel_3049901/365939491.py:31: SyntaxWarning: invalid escape sequence '\\|'\n",
      "  print(ascii_art)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "\n",
    "def print_success_banner(start_time, channel):\n",
    "    # 1. Calculate Duration\n",
    "    duration = time.time() - start_time\n",
    "    \n",
    "    # 2. Calculate Proof Size\n",
    "    # We sum the bytes of all strings sent in the proof\n",
    "    proof_size_bytes = sum(len(entry.encode('utf-8')) for entry in channel.proof)\n",
    "    proof_size_kb = proof_size_bytes / 1024\n",
    "    \n",
    "    # 3. ASCII Art & Colors\n",
    "    GREEN = \"\\033[92m\"\n",
    "    CYAN = \"\\033[96m\"\n",
    "    YELLOW = \"\\033[93m\"\n",
    "    RESET = \"\\033[0m\"\n",
    "    BOLD = \"\\033[1m\"\n",
    "    \n",
    "    ascii_art = f\"\"\"\n",
    "{GREEN}{BOLD}\n",
    "  _____  _____   ____   ____  ______   __      __    _      _____  _____  \n",
    " |  __ \\|  __ \\ / __ \\ / __ \\|  ____|  \\ \\    / /\\  | |    |_   _||  __ \\ \n",
    " | |__) | |__) | |  | | |  | | |__      \\ \\  / /  \\ | |      | |  | |  | |\n",
    " |  ___/|  _  /| |  | | |  | |  __|      \\ \\/ / /\\ \\| |      | |  | |  | |\n",
    " | |    | | \\ \\| |__| | |__| | |          \\  / ____ \\ |____ _| |_ | |__| |\n",
    " |_|    |_|  \\_\\\\____/ \\____/|_|           \\/_/    \\_\\______|_____|_____/ \n",
    "                                                                            \n",
    "{RESET}\"\"\"\n",
    "    \n",
    "    print(ascii_art)\n",
    "    print(f\"{BOLD}Status:{RESET}   {GREEN}VERIFICATION SUCCESSFUL{RESET}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{BOLD}Metrics:{RESET}\")\n",
    "    print(f\"  ‚è±Ô∏è  {CYAN}Time Taken:{RESET}    {duration:.4f} seconds\")\n",
    "    print(f\"  üì¶ {YELLOW}Proof Size:{RESET}    {proof_size_kb:.2f} KB\")\n",
    "    print(f\"  üîê {CYAN}Queries:{RESET}       {constants.N_QUERY}\")\n",
    "    max_constraint_degree = (constants.POSEIDON_TRACE_EVAL_LENGTH - 1) * 5 \n",
    "\n",
    "    # 2. Calculate Probability of Cheating (Soundness Error)\n",
    "    # Rho = Degree / Domain_Size\n",
    "    rho = max_constraint_degree / constants.STATE_EVAL_LENGTH\n",
    "    p_cheat = rho ** constants.N_QUERY\n",
    "    \n",
    "    # 3. Print Code\n",
    "    print(f\"  üé≤ {CYAN}P(Cheating):{RESET}    {p_cheat:.8f} (approx. 1 in {int(1/p_cheat)})\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Optional: Contextualize for the Jury\n",
    "    print(f\"{BOLD}Interpretation:{RESET}\")\n",
    "    if proof_size_kb < 200:\n",
    "        print(\"  ‚úÖ Succinct Proof (Very small size!)\")\n",
    "    else:\n",
    "        print(\"  ‚ö†Ô∏è Large Proof (Consider checking trace/blowup)\")\n",
    "\n",
    "# Call it using your existing timing variable\n",
    "# Make sure you start the timer specifically before verification starts\n",
    "verification_start = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3851f9a1-ea12-4ad0-8414-fcc9b60c6dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = FieldElement.generator()\n",
    "h = FieldElement.generator() ** (3*2**30/(constants.PTRACE_DOMAIN_SIZE*8))\n",
    "gp = FieldElement.generator() ** (3*2**30/(constants.PTRACE_DOMAIN_SIZE))\n",
    "x = [gp**i for i in range(constants.AUTOMATA_TRACE_LENGTH)]\n",
    "z = [gp**i for i in range(constants.POSEIDON_TRACE_EVAL_LENGTH)]\n",
    "mds = generate_cauchy_matrix(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c812fd5b-d91e-4a3a-969e-d20c7dd5d68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "proof_file = open(\"proof.txt\", \"r\")\n",
    "proof = ast.literal_eval(proof_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe9361ce-f327-4263-8af6-f71aeb27816d",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = Channel(proof)\n",
    "v_proof = channel.proof\n",
    "v_c = Channel()\n",
    "v_current_channel_idx = 0\n",
    "v_hash = v_proof[v_current_channel_idx][5:]\n",
    "v_c.send(v_hash)\n",
    "v_current_channel_idx+=1\n",
    "v_state_merkle = v_proof[v_current_channel_idx][5:]\n",
    "v_c.send(v_state_merkle)\n",
    "v_current_channel_idx+=1\n",
    "v_caracter_merkle = v_proof[v_current_channel_idx][5:]\n",
    "v_c.send(v_caracter_merkle)\n",
    "v_current_channel_idx+=1\n",
    "v_transition_merkle = v_proof[v_current_channel_idx][5:]\n",
    "v_c.send(v_transition_merkle)\n",
    "v_current_channel_idx+=1\n",
    "v_ptrace_merkle = v_proof[v_current_channel_idx][5:]\n",
    "v_c.send(v_ptrace_merkle)\n",
    "v_current_channel_idx+=1\n",
    "v_hash_merkle = v_proof[v_current_channel_idx][5:]\n",
    "v_c.send(v_hash_merkle)\n",
    "v_current_channel_idx+=1\n",
    "v_arc_merkle = v_proof[v_current_channel_idx][5:]\n",
    "v_c.send(v_arc_merkle)\n",
    "v_current_channel_idx+=1\n",
    "v_alphas = []\n",
    "for i in range(constants.CONSTRAINTS_LENGTH):\n",
    "    v_a = FieldElement(int(v_proof[v_current_channel_idx][len('receive_random_field_element:'):]))\n",
    "    v_current_channel_idx+=1\n",
    "    v_alphas.append(v_a)\n",
    "#a0 = FieldElement(int(proof[current_channel_idx][len('receive_random_field_element:'):]))\n",
    "#assert(c.receive_random_field_element() == a0)\n",
    "#current_channel_idx+=1\n",
    "#a1 = FieldElement(int(proof[current_channel_idx][len('receive_random_field_element:'):]))\n",
    "#assert(c.receive_random_field_element() == a1)\n",
    "#current_channel_idx+=1\n",
    "#a2 = FieldElement(int(proof[current_channel_idx][len('receive_random_field_element:'):]))\n",
    "#assert(c.receive_random_field_element() == a2)\n",
    "#current_channel_idx+=1\n",
    "#a3 = FieldElement(int(proof[current_channel_idx][len('receive_random_field_element:'):]))\n",
    "#assert(c.receive_random_field_element() == a3)\n",
    "#current_channel_idx+=1\n",
    "#a4 = FieldElement(int(proof[current_channel_idx][len('receive_random_field_element:'):]))\n",
    "#assert(c.receive_random_field_element() == a4)\n",
    "#current_channel_idx+=1\n",
    "cp_merkle_root = v_proof[v_current_channel_idx][len('send:'):]\n",
    "v_current_channel_idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a02f2218-5f5c-402b-a75a-129de14e2140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_FRI_commitment():\n",
    "    global v_proof\n",
    "    global v_current_channel_idx\n",
    "    v_betas = []\n",
    "    v_roots = [cp_merkle_root]\n",
    "    v_l = 0\n",
    "    while v_proof[v_current_channel_idx] != \"send:FINISHED_FRI\":\n",
    "        v_betas.append(FieldElement(int(v_proof[v_current_channel_idx][len('receive_random_field_element:'):])))\n",
    "        v_current_channel_idx+=1\n",
    "        v_roots.append(v_proof[v_current_channel_idx][len('send:'):])\n",
    "        v_current_channel_idx+=1\n",
    "        v_l+=1\n",
    "    v_current_channel_idx+=1\n",
    "    v_poly0 = int(v_proof[v_current_channel_idx][len('send:'):])\n",
    "    v_current_channel_idx+=1\n",
    "    return v_betas,v_roots,v_poly0,v_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a01cfc3b-a6fa-4145-9a9f-941d380144b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_betas,v_roots,v_poly0,v_l = verify_FRI_commitment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa43039f-bd50-4e4a-b11f-8ca2229c71d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_proof(method, parse = None):\n",
    "    global v_current_channel_idx\n",
    "    global v_proof\n",
    "    #print(\"channel\",proof[current_channel_idx], \"method\", method)\n",
    "    v_current_channel_idx+=1\n",
    "    if parse == None:\n",
    "        return v_proof[v_current_channel_idx-1][len(method)+1:]\n",
    "    else:\n",
    "        return parse(v_proof[v_current_channel_idx-1][len(method)+1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffb4334a-62e3-4827-bd09-b9cf4af7aea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_query_decommitment(l):\n",
    "    global current_channel_idx\n",
    "    for query in range(constants.N_QUERY):\n",
    "        # r = int(proof[current_channel_idx][len('receive_random_field_element:'):])\n",
    "        r = parse_proof(\"receive_random_int\", int)\n",
    "        # current_channel_idx+=1\n",
    "        state_x = parse_proof(\"send\", lambda x: FieldElement(int(x)))\n",
    "        #state_x = FieldElement(int(proof[current_channel_idx][len('send:'):]))\n",
    "        #current_channel_idx+=1\n",
    "        state_x_path = parse_proof(\"send\", lambda x: ast.literal_eval(x))\n",
    "        state_x2 = parse_proof(\"send\", lambda x: FieldElement(int(x)))\n",
    "        #state_x = FieldElement(int(proof[current_channel_idx][len('send:'):]))\n",
    "        #current_channel_idx+=1\n",
    "        state_x2_path = parse_proof(\"send\", lambda x: ast.literal_eval(x))\n",
    "        #state_x_path = ast.literal_eval(proof[current_channel_idx][len('send:'):])\n",
    "        #current_channel_idx+=1\n",
    "        assert(verify_decommitment(r,state_x,state_x_path,v_state_merkle))\n",
    "        assert(verify_decommitment(r+8,state_x2,state_x2_path,v_state_merkle))\n",
    "\n",
    "        #caracter_x = FieldElement(int(proof[current_channel_idx][len('send:'):]))\n",
    "        #current_channel_idx+=1\n",
    "        caracter_x = parse_proof(\"send\", lambda x: FieldElement(int(x)))\n",
    "        caracter_x_path = parse_proof(\"send\", lambda x: ast.literal_eval(x))\n",
    "        #caracter_x_path = proof[current_channel_idx][len('send:'):]\n",
    "        #current_channel_idx+=1\n",
    "        assert(verify_decommitment(r,caracter_x,caracter_x_path,v_caracter_merkle))\n",
    "\n",
    "        transition_x = parse_proof(\"send\", lambda x: FieldElement(int(x)))\n",
    "        transition_x_path = parse_proof(\"send\", lambda x: ast.literal_eval(x))\n",
    "        assert(verify_decommitment(constants.STATE_EVAL_LENGTH*r+r,transition_x,transition_x_path,v_transition_merkle))\n",
    "\n",
    "        poseidon_x = []\n",
    "        poseidon_path = []\n",
    "        poseidon_next_x = []\n",
    "        poseidon_next_path = []\n",
    "        hash_x = []\n",
    "        hash_path = []\n",
    "        arc_x = []\n",
    "        arc_path = []\n",
    "        \n",
    "        for i in range(constants.T):\n",
    "            poseidon_x.append(parse_proof(\"send\", lambda x: FieldElement(int(x))))\n",
    "            poseidon_path.append(parse_proof(\"send\", lambda x: ast.literal_eval(x)))\n",
    "            assert(verify_decommitment(i*constants.EVAL_DOMAIN_LENGTH + r,poseidon_x[-1],poseidon_path[-1],v_ptrace_merkle))\n",
    "\n",
    "            poseidon_next_x.append(parse_proof(\"send\", lambda x: FieldElement(int(x))))\n",
    "            poseidon_next_path.append(parse_proof(\"send\", lambda x: ast.literal_eval(x)))\n",
    "            assert(verify_decommitment(i*constants.EVAL_DOMAIN_LENGTH  + r + 8,poseidon_next_x[-1],poseidon_next_path[-1],v_ptrace_merkle))\n",
    "\n",
    "            hash_x.append(parse_proof(\"send\", lambda x: FieldElement(int(x))))\n",
    "            hash_path.append(parse_proof(\"send\", lambda x: ast.literal_eval(x)))\n",
    "            assert(verify_decommitment(i*constants.EVAL_DOMAIN_LENGTH  + r,hash_x[-1],hash_path[-1],v_hash_merkle))\n",
    "\n",
    "            arc_x.append(parse_proof(\"send\", lambda x: FieldElement(int(x))))\n",
    "            arc_path.append(parse_proof(\"send\", lambda x: ast.literal_eval(x)))\n",
    "            assert(verify_decommitment(i*constants.EVAL_DOMAIN_LENGTH  + r,arc_x[-1],arc_path[-1],v_arc_merkle))\n",
    "        \n",
    "        #transition_x = FieldElement(int(proof[current_channel_idx][len('send:'):]))\n",
    "        #current_channel_idx+=1\n",
    "        #transition_x_path = proof[current_channel_idx][len('send:'):]\n",
    "        #current_channel_idx+=1\n",
    "\n",
    "        layers = []\n",
    "        layer_paths = []\n",
    "\n",
    "        length = 2**(v_l+1)\n",
    "        cps = []\n",
    "            \n",
    "        for j in range(0,l):\n",
    "            idx = r % length\n",
    "            sib_idx = (r + length // 2) % length\n",
    "            layer_x = parse_proof(\"send\", lambda x: FieldElement(int(x)))\n",
    "            #layer_x = int(proof[current_channel_idx][len('send:'):])\n",
    "            #current_channel_idx+=1\n",
    "            layer_x_path = parse_proof(\"send\",  lambda x: ast.literal_eval(x))\n",
    "            assert(verify_decommitment(idx,layer_x,layer_x_path,v_roots[j]))\n",
    "            #layer_x_path = proof[current_channel_idx][len('send:'):]\n",
    "            #current_channel_idx+=1\n",
    "            layer_sibx = parse_proof(\"send\", lambda x: FieldElement(int(x)))\n",
    "            #layer_sibx = int(proof[current_channel_idx][len('send:'):])\n",
    "            #current_channel_idx+=1\n",
    "            #layer_sibx_path = proof[current_channel_idx][len('send:'):]\n",
    "            layer_sibx_path = parse_proof(\"send\",  lambda x: ast.literal_eval(x))\n",
    "            assert(verify_decommitment(sib_idx,layer_sibx,layer_sibx_path,v_roots[j]))\n",
    "            e = (w*h**idx)**(2**j)\n",
    "            \n",
    "            g_x = (layer_x + layer_sibx)/FieldElement(2)\n",
    "            h_x = (layer_x - layer_sibx)/(2*e) \n",
    "            cp_ip1 = g_x + v_betas[j]*h_x\n",
    "            cps.append(cp_ip1)\n",
    "            \n",
    "            if j == 0:\n",
    "                initial_constraint = (state_x-constants.state_map['q0'])/(e-1)\n",
    "                Z_G = FieldElement(1)\n",
    "                for i in range(len(x)):\n",
    "                  Z_G = Z_G * (e-x[i])\n",
    "                ap = FieldElement(1)\n",
    "                for c in constants.alphabet:\n",
    "                    ap = ap * (caracter_x - constants.caracter_map[c])\n",
    "                caracter_constraint = ap/Z_G\n",
    "                ap = FieldElement(1)\n",
    "                for f in constants.accept_states:\n",
    "                  ap = ap * (state_x - constants.state_map[f])\n",
    "                accepting_constraint = ap/(e-x[-1])\n",
    "                step_constraint = (state_x2 - transition_x)/(Z_G/(e-x[-1]))\n",
    "                X_G = FieldElement(1)\n",
    "                Y_G = FieldElement(1)\n",
    "                for i in range(constants.POSEIDON_TRACE_EVAL_LENGTH-1):\n",
    "                    round_x = i%(constants.r_f+constants.r_p)\n",
    "                    if(round_x < constants.r_f/2 or round_x >= constants.r_f/2+constants.r_p):\n",
    "                      X_G = X_G * (e-z[i])\n",
    "                    else:\n",
    "                      Y_G = Y_G * (e-z[i])\n",
    "                v_poseidon_full_round = mds@[(poseidon_x[j] + hash_x[j] + arc_x[j])**5 for j in range(0,8)]\n",
    "                v_poseidon_partial_round = mds@[(poseidon_x[j] + hash_x[j] + arc_x[j])**(5 if j == 0 else 1) for j in range(0,8)]\n",
    "                poseidon_full_round_cr = [(poseidon_next_x[j] - v_poseidon_full_round[j])/X_G for j in range(constants.T)]\n",
    "                poseidon_partial_round_cr = [(poseidon_next_x[j] - v_poseidon_partial_round[j])/Y_G for j in range(constants.T)]\n",
    "                poseidon_initial_cr = [poseidon_x[j]/(e-1) for j in range(constants.T)]\n",
    "                poseidon_output_cr = (poseidon_x[0]-FieldElement(int(v_hash)))/(e-z[-1])\n",
    "\n",
    "                v_ps = [poseidon_output_cr, initial_constraint, caracter_constraint, accepting_constraint, step_constraint, *poseidon_initial_cr, *poseidon_full_round_cr, *poseidon_partial_round_cr]\n",
    "                cp_e = reduce(lambda x, y: x+y,map(lambda a, p: a*p, v_alphas, v_ps),FieldElement(0))\n",
    "                assert(cp_e == layer_x)\n",
    "            else:\n",
    "                assert(cps[j-1] == layer_x)\n",
    "            \n",
    "            layers.append((layer_x,layer_sibx))\n",
    "            layer_paths.append((layer_x_path, layer_sibx_path))\n",
    "            length //= 2\n",
    "\n",
    "        last_layer_x = parse_proof(\"send\", int)\n",
    "        assert(cps[-1] == last_layer_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f20dc91-1e4c-41b4-a251-bd3397d7c72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1161095951\n",
      "-1161095951\n",
      "-1161095951\n"
     ]
    }
   ],
   "source": [
    "verify_query_decommitment(v_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d430c846-f2d2-4c0f-a5f7-e243a68da01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[92m\u001b[1m\n",
      "  _____  _____   ____   ____  ______   __      __    _      _____  _____  \n",
      " |  __ \\|  __ \\ / __ \\ / __ \\|  ____|  \\ \\    / /\\  | |    |_   _||  __ \\ \n",
      " | |__) | |__) | |  | | |  | | |__      \\ \\  / /  \\ | |      | |  | |  | |\n",
      " |  ___/|  _  /| |  | | |  | |  __|      \\ \\/ / /\\ \\| |      | |  | |  | |\n",
      " | |    | | \\ \\| |__| | |__| | |          \\  / ____ \\ |____ _| |_ | |__| |\n",
      " |_|    |_|  \\_\\____/ \\____/|_|           \\/_/    \\_\\______|_____|_____/ \n",
      "\n",
      "\u001b[0m\n",
      "\u001b[1mStatus:\u001b[0m   \u001b[92mVERIFICATION SUCCESSFUL\u001b[0m\n",
      "--------------------------------------------------\n",
      "\u001b[1mMetrics:\u001b[0m\n",
      "  ‚è±Ô∏è  \u001b[96mTime Taken:\u001b[0m    4.7995 seconds\n",
      "  üì¶ \u001b[93mProof Size:\u001b[0m    132.07 KB\n",
      "  üîê \u001b[96mQueries:\u001b[0m       3\n",
      "  üé≤ \u001b[96mP(Cheating):\u001b[0m    0.03197056 (approx. 1 in 31)\n",
      "--------------------------------------------------\n",
      "\u001b[1mInterpretation:\u001b[0m\n",
      "  ‚úÖ Succinct Proof (Very small size!)\n"
     ]
    }
   ],
   "source": [
    "print_success_banner(verification_start, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0db100-4cfb-4fd7-80b7-96fcfe3ffa92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
