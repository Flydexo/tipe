{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dd58604-2ccf-45e2-9296-238fdecf3393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import constants\n",
    "from constants import blowup_factor\n",
    "from channel import Channel\n",
    "from field import FieldElement\n",
    "from merkle import verify_decommitment\n",
    "from poseidon import generate_cauchy_matrix\n",
    "from functools import reduce\n",
    "from utils import Automata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27a6712a-42e1-4187-89c5-1a3210589c5d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:29: SyntaxWarning: invalid escape sequence '\\|'\n",
      "<>:29: SyntaxWarning: invalid escape sequence '\\|'\n",
      "/var/folders/ly/15y4sjzx7mbgxkqgc6cmh3b40000gn/T/ipykernel_63084/2931931020.py:29: SyntaxWarning: invalid escape sequence '\\|'\n",
      "  {RESET}\"\"\"\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "\n",
    "def print_success_banner(start_time, channel, EVAL_DOMAIN_LENGTH, POSEIDON_TRACE_EVAL_LENGTH):\n",
    "    # 1. Calculate Duration\n",
    "    duration = time.time() - start_time\n",
    "    \n",
    "    # 2. Calculate Proof Size\n",
    "    # We sum the bytes of all strings sent in the proof\n",
    "    proof_size_bytes = sum(len(entry.encode('utf-8')) for entry in channel.proof)\n",
    "    proof_size_kb = proof_size_bytes / 1024\n",
    "    \n",
    "    # 3. ASCII Art & Colors\n",
    "    GREEN = \"\\033[92m\"\n",
    "    CYAN = \"\\033[96m\"\n",
    "    YELLOW = \"\\033[93m\"\n",
    "    RESET = \"\\033[0m\"\n",
    "    BOLD = \"\\033[1m\"\n",
    "    \n",
    "    ascii_art = f\"\"\"\n",
    "{GREEN}{BOLD}\n",
    "  _____  _____   ____   ____  ______   __      __    _      _____  _____  \n",
    " |  __ \\|  __ \\ / __ \\ / __ \\|  ____|  \\ \\    / /\\  | |    |_   _||  __ \\ \n",
    " | |__) | |__) | |  | | |  | | |__      \\ \\  / /  \\ | |      | |  | |  | |\n",
    " |  ___/|  _  /| |  | | |  | |  __|      \\ \\/ / /\\ \\| |      | |  | |  | |\n",
    " | |    | | \\ \\| |__| | |__| | |          \\  / ____ \\ |____ _| |_ | |__| |\n",
    " |_|    |_|  \\_\\\\____/ \\____/|_|           \\/_/    \\_\\______|_____|_____/ \n",
    "                                                                            \n",
    "{RESET}\"\"\"\n",
    "    \n",
    "    print(ascii_art)\n",
    "    print(f\"{BOLD}Status:{RESET}   {GREEN}VERIFICATION SUCCESSFUL{RESET}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{BOLD}Metrics:{RESET}\")\n",
    "    print(f\"  ‚è±Ô∏è  {CYAN}Time Taken:{RESET}    {duration:.4f} seconds\")\n",
    "    print(f\"  üì¶ {YELLOW}Proof Size:{RESET}    {proof_size_kb:.2f} KB\")\n",
    "    print(f\"  üîê {CYAN}Queries:{RESET}       {constants.N_QUERY}\")\n",
    "    max_constraint_degree = (POSEIDON_TRACE_EVAL_LENGTH - 1) * 5 \n",
    "\n",
    "    # 2. Calculate Probability of Cheating (Soundness Error)\n",
    "    # Rho = Degree / Domain_Size\n",
    "    rho = max_constraint_degree / EVAL_DOMAIN_LENGTH\n",
    "    p_cheat = rho ** constants.N_QUERY\n",
    "    \n",
    "    # 3. Print Code\n",
    "    print(f\"  üé≤ {CYAN}P(Cheating):{RESET}    {p_cheat:.8f} (approx. 1 in {int(1/p_cheat)})\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Optional: Contextualize for the Jury\n",
    "    print(f\"{BOLD}Interpretation:{RESET}\")\n",
    "    if proof_size_kb < 200:\n",
    "        print(\"  ‚úÖ Succinct Proof (Very small size!)\")\n",
    "    else:\n",
    "        print(\"  ‚ö†Ô∏è Large Proof (Consider checking trace/blowup)\")\n",
    "\n",
    "# Call it using your existing timing variable\n",
    "# Make sure you start the timer specifically before verification starts\n",
    "verification_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c812fd5b-d91e-4a3a-969e-d20c7dd5d68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "proof_file = open(\"proof.txt\", \"r\")\n",
    "proof = ast.literal_eval(proof_file.read())\n",
    "automata = Automata.from_json(open(\"automata.json\", \"r\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6de09ec9-8c7b-4010-b8de-918d24610f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_proof(method, parse = None):\n",
    "    global v_current_channel_idx\n",
    "    global v_proof\n",
    "    #print(\"channel\",proof[current_channel_idx], \"method\", method)\n",
    "    v_current_channel_idx+=1\n",
    "    if parse == None:\n",
    "        return v_proof[v_current_channel_idx-1][len(method)+1:]\n",
    "    else:\n",
    "        return parse(v_proof[v_current_channel_idx-1][len(method)+1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe9361ce-f327-4263-8af6-f71aeb27816d",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = Channel(proof)\n",
    "v_proof = channel.proof\n",
    "v_c = Channel()\n",
    "v_current_channel_idx = 0\n",
    "PTRACE_DOMAIN_SIZE=parse_proof(\"send\", lambda x: int(x))\n",
    "POSEIDON_TRACE_EVAL_LENGTH=parse_proof(\"send\", lambda x: int(x))\n",
    "EVAL_DOMAIN_LENGTH=parse_proof(\"send\", lambda x: int(x))\n",
    "AUTOMATA_TRACE_LENGTH=parse_proof(\"send\", lambda x: int(x))\n",
    "v_hash = v_proof[v_current_channel_idx][5:]\n",
    "v_c.send(v_hash)\n",
    "v_current_channel_idx+=1\n",
    "v_state_merkle = v_proof[v_current_channel_idx][5:]\n",
    "v_c.send(v_state_merkle)\n",
    "v_current_channel_idx+=1\n",
    "v_caracter_merkle = v_proof[v_current_channel_idx][5:]\n",
    "v_c.send(v_caracter_merkle)\n",
    "v_current_channel_idx+=1\n",
    "v_transition_merkle = v_proof[v_current_channel_idx][5:]\n",
    "v_c.send(v_transition_merkle)\n",
    "v_current_channel_idx+=1\n",
    "v_ptrace_merkle = v_proof[v_current_channel_idx][5:]\n",
    "v_c.send(v_ptrace_merkle)\n",
    "v_current_channel_idx+=1\n",
    "v_hash_merkle = v_proof[v_current_channel_idx][5:]\n",
    "v_c.send(v_hash_merkle)\n",
    "v_current_channel_idx+=1\n",
    "v_arc_merkle = v_proof[v_current_channel_idx][5:]\n",
    "v_c.send(v_arc_merkle)\n",
    "v_current_channel_idx+=1\n",
    "v_alphas = []\n",
    "for i in range(constants.CONSTRAINTS_LENGTH):\n",
    "    v_a = FieldElement(int(v_proof[v_current_channel_idx][len('receive_random_field_element:'):]))\n",
    "    v_current_channel_idx+=1\n",
    "    v_alphas.append(v_a)\n",
    "#a0 = FieldElement(int(proof[current_channel_idx][len('receive_random_field_element:'):]))\n",
    "#assert(c.receive_random_field_element() == a0)\n",
    "#current_channel_idx+=1\n",
    "#a1 = FieldElement(int(proof[current_channel_idx][len('receive_random_field_element:'):]))\n",
    "#assert(c.receive_random_field_element() == a1)\n",
    "#current_channel_idx+=1\n",
    "#a2 = FieldElement(int(proof[current_channel_idx][len('receive_random_field_element:'):]))\n",
    "#assert(c.receive_random_field_element() == a2)\n",
    "#current_channel_idx+=1\n",
    "#a3 = FieldElement(int(proof[current_channel_idx][len('receive_random_field_element:'):]))\n",
    "#assert(c.receive_random_field_element() == a3)\n",
    "#current_channel_idx+=1\n",
    "#a4 = FieldElement(int(proof[current_channel_idx][len('receive_random_field_element:'):]))\n",
    "#assert(c.receive_random_field_element() == a4)\n",
    "#current_channel_idx+=1\n",
    "cp_merkle_root = v_proof[v_current_channel_idx][len('send:'):]\n",
    "v_current_channel_idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a7416d2-3b2e-4022-91db-e3bb8d4f66d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = FieldElement.generator()\n",
    "h = FieldElement.generator() ** (3*2**30/(PTRACE_DOMAIN_SIZE*blowup_factor))\n",
    "gp = FieldElement.generator() ** (3*2**30/(PTRACE_DOMAIN_SIZE))\n",
    "\n",
    "#def x(i):\n",
    "#    return gp**i\n",
    "\n",
    "def x(i):\n",
    "    return gp**(i%AUTOMATA_TRACE_LENGTH)\n",
    "\n",
    "def z(i):\n",
    "    return gp**(i%POSEIDON_TRACE_EVAL_LENGTH)\n",
    "\n",
    "#x = [gp**i for i in range(AUTOMATA_TRACE_LENGTH)]\n",
    "#z = [gp**i for i in range(POSEIDON_TRACE_EVAL_LENGTH)]\n",
    "mds = generate_cauchy_matrix(constants.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a02f2218-5f5c-402b-a75a-129de14e2140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_FRI_commitment():\n",
    "    global v_proof\n",
    "    global v_current_channel_idx\n",
    "    v_betas = []\n",
    "    v_roots = [cp_merkle_root]\n",
    "    v_l = 0\n",
    "    while v_proof[v_current_channel_idx] != \"send:FINISHED_FRI\":\n",
    "        v_betas.append(FieldElement(int(v_proof[v_current_channel_idx][len('receive_random_field_element:'):])))\n",
    "        v_current_channel_idx+=1\n",
    "        v_roots.append(v_proof[v_current_channel_idx][len('send:'):])\n",
    "        v_current_channel_idx+=1\n",
    "        v_l+=1\n",
    "    v_current_channel_idx+=1\n",
    "    v_poly0 = int(v_proof[v_current_channel_idx][len('send:'):])\n",
    "    v_current_channel_idx+=1\n",
    "    return v_betas,v_roots,v_poly0,v_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a01cfc3b-a6fa-4145-9a9f-941d380144b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_betas,v_roots,v_poly0,v_l = verify_FRI_commitment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffb4334a-62e3-4827-bd09-b9cf4af7aea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_query_decommitment(l):\n",
    "    global current_channel_idx\n",
    "    for query in range(constants.N_QUERY):\n",
    "        # r = int(proof[current_channel_idx][len('receive_random_field_element:'):])\n",
    "        r = parse_proof(\"receive_random_int\", int)\n",
    "        # current_channel_idx+=1\n",
    "        state_x = parse_proof(\"send\", lambda x: FieldElement(int(x)))\n",
    "        #state_x = FieldElement(int(proof[current_channel_idx][len('send:'):]))\n",
    "        #current_channel_idx+=1\n",
    "        state_x_path = parse_proof(\"send\", lambda x: ast.literal_eval(x))\n",
    "        state_x2 = parse_proof(\"send\", lambda x: FieldElement(int(x)))\n",
    "        #state_x = FieldElement(int(proof[current_channel_idx][len('send:'):]))\n",
    "        #current_channel_idx+=1\n",
    "        state_x2_path = parse_proof(\"send\", lambda x: ast.literal_eval(x))\n",
    "        #state_x_path = ast.literal_eval(proof[current_channel_idx][len('send:'):])\n",
    "        #current_channel_idx+=1\n",
    "        assert(verify_decommitment(r,state_x,state_x_path,v_state_merkle))\n",
    "        assert(verify_decommitment((r+blowup_factor),state_x2,state_x2_path,v_state_merkle))\n",
    "\n",
    "        #caracter_x = FieldElement(int(proof[current_channel_idx][len('send:'):]))\n",
    "        #current_channel_idx+=1\n",
    "        caracter_x = parse_proof(\"send\", lambda x: FieldElement(int(x)))\n",
    "        caracter_x_path = parse_proof(\"send\", lambda x: ast.literal_eval(x))\n",
    "        #caracter_x_path = proof[current_channel_idx][len('send:'):]\n",
    "        #current_channel_idx+=1\n",
    "        assert(verify_decommitment(r,caracter_x,caracter_x_path,v_caracter_merkle))\n",
    "\n",
    "        transition_x = parse_proof(\"send\", lambda x: FieldElement(int(x)))\n",
    "        transition_x_path = parse_proof(\"send\", lambda x: ast.literal_eval(x))\n",
    "        assert(verify_decommitment((EVAL_DOMAIN_LENGTH*r+r),transition_x,transition_x_path,v_transition_merkle))\n",
    "\n",
    "        poseidon_x = []\n",
    "        poseidon_path = []\n",
    "        poseidon_next_x = []\n",
    "        poseidon_next_path = []\n",
    "        hash_x = []\n",
    "        hash_path = []\n",
    "        arc_x = []\n",
    "        arc_path = []\n",
    "        \n",
    "        for i in range(constants.T):\n",
    "            poseidon_x.append(parse_proof(\"send\", lambda x: FieldElement(int(x))))\n",
    "            poseidon_path.append(parse_proof(\"send\", lambda x: ast.literal_eval(x)))\n",
    "            assert(verify_decommitment((i*EVAL_DOMAIN_LENGTH + (r)),poseidon_x[-1],poseidon_path[-1],v_ptrace_merkle))\n",
    "\n",
    "            poseidon_next_x.append(parse_proof(\"send\", lambda x: FieldElement(int(x))))\n",
    "            poseidon_next_path.append(parse_proof(\"send\", lambda x: ast.literal_eval(x)))\n",
    "            assert(verify_decommitment((i*EVAL_DOMAIN_LENGTH  + ((r + blowup_factor))),poseidon_next_x[-1],poseidon_next_path[-1],v_ptrace_merkle))\n",
    "\n",
    "            hash_x.append(parse_proof(\"send\", lambda x: FieldElement(int(x))))\n",
    "            hash_path.append(parse_proof(\"send\", lambda x: ast.literal_eval(x)))\n",
    "            assert(verify_decommitment((i*EVAL_DOMAIN_LENGTH  + (r)),hash_x[-1],hash_path[-1],v_hash_merkle))\n",
    "\n",
    "            arc_x.append(parse_proof(\"send\", lambda x: FieldElement(int(x))))\n",
    "            arc_path.append(parse_proof(\"send\", lambda x: ast.literal_eval(x)))\n",
    "            assert(verify_decommitment((i*EVAL_DOMAIN_LENGTH  + (r)),arc_x[-1],arc_path[-1],v_arc_merkle))\n",
    "        \n",
    "        #transition_x = FieldElement(int(proof[current_channel_idx][len('send:'):]))\n",
    "        #current_channel_idx+=1\n",
    "        #transition_x_path = proof[current_channel_idx][len('send:'):]\n",
    "        #current_channel_idx+=1\n",
    "\n",
    "        layers = []\n",
    "        layer_paths = []\n",
    "\n",
    "        length = 2**(v_l+1)\n",
    "        cps = []\n",
    "            \n",
    "        for j in range(0,l):\n",
    "            idx = r % length\n",
    "            sib_idx = (r + length // 2) % length\n",
    "            layer_x = parse_proof(\"send\", lambda x: FieldElement(int(x)))\n",
    "            #layer_x = int(proof[current_channel_idx][len('send:'):])\n",
    "            #current_channel_idx+=1\n",
    "            layer_x_path = parse_proof(\"send\",  lambda x: ast.literal_eval(x))\n",
    "            assert(verify_decommitment(idx,layer_x,layer_x_path,v_roots[j]))\n",
    "            #layer_x_path = proof[current_channel_idx][len('send:'):]\n",
    "            #current_channel_idx+=1\n",
    "            layer_sibx = parse_proof(\"send\", lambda x: FieldElement(int(x)))\n",
    "            #layer_sibx = int(proof[current_channel_idx][len('send:'):])\n",
    "            #current_channel_idx+=1\n",
    "            #layer_sibx_path = proof[current_channel_idx][len('send:'):]\n",
    "            layer_sibx_path = parse_proof(\"send\",  lambda x: ast.literal_eval(x))\n",
    "            assert(verify_decommitment(sib_idx,layer_sibx,layer_sibx_path,v_roots[j]))\n",
    "            e = (w*h**idx)**(2**j)\n",
    "            \n",
    "            g_x = (layer_x + layer_sibx)/FieldElement(2)\n",
    "            h_x = (layer_x - layer_sibx)/(2*e) \n",
    "            cp_ip1 = g_x + v_betas[j]*h_x\n",
    "            cps.append(cp_ip1)\n",
    "            \n",
    "            if j == 0:\n",
    "                initial_constraint = (state_x-automata.state_map['q0'])/(e-1)\n",
    "                Z_G = FieldElement(1)\n",
    "                for i in range(AUTOMATA_TRACE_LENGTH):\n",
    "                  Z_G = Z_G * (e-x(i))\n",
    "                ap = FieldElement(1)\n",
    "                for c in automata.alphabet:\n",
    "                    ap = ap * (caracter_x - automata.caracter_map[c])\n",
    "                caracter_constraint = ap/Z_G\n",
    "                ap = FieldElement(1)\n",
    "                for f in automata.accept_states:\n",
    "                  ap = ap * (state_x - automata.state_map[f])\n",
    "                accepting_constraint = ap/(e-x(-1))\n",
    "                step_constraint = (state_x2 - transition_x)/(Z_G/(e-x(-1)))\n",
    "                X_G = FieldElement(1)\n",
    "                Y_G = FieldElement(1)\n",
    "                for i in range(POSEIDON_TRACE_EVAL_LENGTH-1):\n",
    "                    round_x = i%(constants.r_f+constants.r_p)\n",
    "                    if(round_x < constants.r_f/2 or round_x >= constants.r_f/2+constants.r_p):\n",
    "                      X_G = X_G * (e-z(i))\n",
    "                    else:\n",
    "                      Y_G = Y_G * (e-z(i))\n",
    "                v_poseidon_full_round = mds@[(poseidon_x[j] + hash_x[j] + arc_x[j])**5 for j in range(constants.T)]\n",
    "                v_poseidon_partial_round = mds@[(poseidon_x[j] + hash_x[j] + arc_x[j])**(5 if j == 0 else 1) for j in range(constants.T)]\n",
    "                poseidon_full_round_cr = [(poseidon_next_x[j] - v_poseidon_full_round[j])/X_G for j in range(constants.T)]\n",
    "                poseidon_partial_round_cr = [(poseidon_next_x[j] - v_poseidon_partial_round[j])/Y_G for j in range(constants.T)]\n",
    "                poseidon_initial_cr = [poseidon_x[j]/(e-1) for j in range(constants.T)]\n",
    "                poseidon_output_cr = (poseidon_x[0]-FieldElement(int(v_hash)))/(e-z(-1))\n",
    "\n",
    "                v_ps = [poseidon_output_cr, initial_constraint, caracter_constraint, accepting_constraint, step_constraint, *poseidon_initial_cr, *poseidon_full_round_cr, *poseidon_partial_round_cr]\n",
    "                cp_e = reduce(lambda x, y: x+y,map(lambda a, p: a*p, v_alphas, v_ps),FieldElement(0))\n",
    "                assert(cp_e == layer_x)\n",
    "            else:\n",
    "                assert(cps[j-1] == layer_x)\n",
    "            \n",
    "            layers.append((layer_x,layer_sibx))\n",
    "            layer_paths.append((layer_x_path, layer_sibx_path))\n",
    "            length //= 2\n",
    "\n",
    "        last_layer_x = parse_proof(\"send\", int)\n",
    "        assert(cps[-1] == last_layer_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f20dc91-1e4c-41b4-a251-bd3397d7c72b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mverify_query_decommitment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv_l\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 84\u001b[39m, in \u001b[36mverify_query_decommitment\u001b[39m\u001b[34m(l)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m#layer_sibx = int(proof[current_channel_idx][len('send:'):])\u001b[39;00m\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m#current_channel_idx+=1\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m#layer_sibx_path = proof[current_channel_idx][len('send:'):]\u001b[39;00m\n\u001b[32m     83\u001b[39m layer_sibx_path = parse_proof(\u001b[33m\"\u001b[39m\u001b[33msend\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;28;01mlambda\u001b[39;00m x: ast.literal_eval(x))\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m(verify_decommitment(sib_idx,layer_sibx,layer_sibx_path,v_roots[j]))\n\u001b[32m     85\u001b[39m e = (w*h**idx)**(\u001b[32m2\u001b[39m**j)\n\u001b[32m     87\u001b[39m g_x = (layer_x + layer_sibx)/FieldElement(\u001b[32m2\u001b[39m)\n",
      "\u001b[31mAssertionError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "verify_query_decommitment(v_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d430c846-f2d2-4c0f-a5f7-e243a68da01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_success_banner(verification_start, channel, EVAL_DOMAIN_LENGTH, POSEIDON_TRACE_EVAL_LENGTH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
